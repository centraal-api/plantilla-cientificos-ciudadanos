{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: Antes de usar el notebook, asegurase que se tiene seleccionado el `kernel` llamado `Python 3.9.13`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalación de la librerias.\n",
    "%pip install -U setuptools wheel\n",
    "%pip install azure-datalake-utils\n",
    "%pip install pandas-profiling\n",
    "%pip install autogluon==0.5.2\n",
    "%pip install flaml==1.0.12\n",
    "# Reinciar el kernel de manera automaticamente.\n",
    "# La celda queda como con error, pero se puede continuar.\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, se va abrir un navegador, el cualquier va requerir autenticación con el directorio activo de Haceb. Por favor usar las credenciales con las que acceden a aplicativos como `office365`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure_datalake_utils import Datalake\n",
    "from pandas_profiling import ProfileReport\n",
    "# configuración del datalake.\n",
    "STORAGE_NAME = {{cookiecutter.nombre_datalake}}\n",
    "dl = Datalake(STORAGE_NAME, {{cookiecutter.tenant}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {{cookiecutter.nombre_notebook}}\n",
    "\n",
    "Autora/Autor: {{cookiecutter.nombre_autor}}\n",
    "\n",
    "Correo: {{cookiecutter.correo_electronico}}\n",
    "\n",
    "Area: {{cookiecutter.area}}\n",
    "\n",
    "{{cookiecutter.descripcion_corta_notebook}}\n",
    "\n",
    "El notebook tiene las siguiente secciones, estas son una sugerencia para mantener organizados todos los proyectos.\n",
    "\n",
    "1. Lectura de archivos desde el datalake.\n",
    "2. Exploración de datos.\n",
    "3. Transformación de datos (incluyendo escritura hacia el datalake).\n",
    "4. Entrenamiento y validación de modelos.\n",
    "5. Generación de predicciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivos desde el datalake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que en el datalake tenemos dos tipos de contenedores/carpetas:\n",
    " \n",
    "- Contenedores curados: Se pueden reconocer por que tienen la palabra `curated` en su nombre. Algunos ejemplos: `hacebanalitica-curated-calidad`, `hacebanalitica-curated-servicio`. Estos contenedores tienen las siguiente reglas:\n",
    "    - Solo es posible leer información y no escribir.\n",
    "    - Cualquier modificación que se necesite en los archivos, debe ser coordinada con el equipo de arquitectura.\n",
    "- Contenedores de usuario: Se pueden reconcer por que tiene la palabra `user` en su nombre. Algunos ejemplos: `hacebanalitica-user-calidad`, `hacebanalitica-user-cientificos`. Estos contenedores tienen las siguiente reglas:\n",
    "    - Es posible leer y escribir información.\n",
    "    - La área correspondiente (ejemplo `calidad`), es la dueña de la información y pueden definir los cambios necesarios en coordinación con el equipo correspondiente.\n",
    "    - Si se encuentran en un proceso de experimentación, tratar de seguir el siguiente orden de prioridad:\n",
    "        - Usar el contenedor del área, ejemplo si el proyecto es de `calidad`, usar el contenedor `hacebanalitica-user-calidad`\n",
    "        - Si no se tiene disponibilidad del contenedor del area, usar `hacebanalitica-user-cientificos`. En futuros avances requerir al equipo de TI/Arquitectura la creación de un contenedor de usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_base = dl.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_excel = dl.read_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de datos\n",
    "\n",
    "Es cualquier experimento o proyecto, es ideal dejar en evidencia la descripción de los archivos que se van a usar. Se sugiere que esta exploración se realice usando la libreria [Pandas Profiling](https://pandas-profiling.ydata.ai/docs/master/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(informacion_base, title=\"Exploracion de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ver el reporte, por favor condensar las principales conclusiones de la exploración de datos, enfocarse en:\n",
    "\n",
    "1. Calidad de datos:\n",
    "    1. ¿Hay variables con valores faltantes?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "    2. ¿Hay variables con valores atípicos?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "2. Tendencias:\n",
    "    1. ¿Hay variables que tengan tendencias, ejemplo valores que se repiten mucho, o muy cercanos?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "3. Patrones insuales:\n",
    "    1. En problemas de clasificación, ¿hay clases que tengan más muestras que otras?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "    2. En problema de regresión, ¿hay meses o epocas del año que tengan más valores?\n",
    "\n",
    "    [escribir propias conclusiones]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de datos\n",
    "\n",
    "En esta sección se deben aplicar las transformaciones que hayan a lugar. En lo posible solo usar operaciones de [Pandas](https://pandas.pydata.org/).\n",
    "\n",
    "Se muestran algunos ejemplos que sirven de inspiración, pero se sugiere explorar mucho más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover duplicados.\n",
    "informacion_base_dedup = informacion_base.drop_duplicates([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar valores.\n",
    "informacion_base_dedup = informacion_base.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teemplazar valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenombrar columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizar variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer muestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir dos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablas pivote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer Melt de dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validación de modelos\n",
    "\n",
    "En esta sección concentrarse en entrenar y validar el modelo. Dentro de esta sección se sugiere:\n",
    "\n",
    "1. Realizar la división de datos, conservar al menos un 10% de datos que no se usaran en el entrenamiento.\n",
    "2. Realizar entrenamiento usando herramientas AutoML. De esta manera la selección de parametros y modelos sera más eficiente. En la plantilla se sugiere usar las siguientes librerias:\n",
    "    1. [Fast Library for Automated Machine Learning & Tunning](https://microsoft.github.io/FLAML/).\n",
    "    2. [AutoGluon](https://auto.gluon.ai/stable/index.html).\n",
    "\n",
    "En las siguiente secciones se muestran algunos ejemplos, para inspiarar el uso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificación FLAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificación AutoGluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión con FLAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión con AutoGluon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de predicciones\n",
    "\n",
    "Una vez se tenga el modelo seleccionado, las predicciones deben recibir las caracteristicas. Se sugiere a esas caracteristicas agregar como columna el valor predicho y guardar esas predicciones dentro del datalake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b145243b2ff1142fe66038d6c3bd724d42c01f344fdc8044c68da453fb6fddb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
