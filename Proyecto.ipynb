{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: Antes de usar el notebook, asegurase que se tiene seleccionado el `kernel` llamado `Python 3.9.13`.\n",
    "\n",
    "NOTEBOOK creado por medio del comando `cookiecutter gh:centraal-api/plantilla-cientificos-ciudadanos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: joblib~=1.1.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.1.0)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.13.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (6.0)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.7.5)\n",
      "Requirement already satisfied: pydantic<1.10,>=1.8.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.9.2)\n",
      "Requirement already satisfied: missingno<0.6,>=0.4.2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.5.1)\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.9.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode==0.2.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.23.2)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.12.2)\n",
      "Requirement already satisfied: matplotlib<3.6,>=3.2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (3.5.3)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.5,>1.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: seaborn<0.12,>=0.10.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (0.11.2)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (2.28.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (3.1.2)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (4.64.1)\n",
      "Requirement already satisfied: multimethod<1.9,>=1.4 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas-profiling) (1.8)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (2.8.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (9.2.0)\n",
      "Requirement already satisfied: imagehash in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from visions[type_image_path]==0.7.5->pandas-profiling) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (4.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from matplotlib<3.6,>=3.2->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas!=1.4.0,<1.5,>1.1->pandas-profiling) (2022.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pydantic<1.10,>=1.8.1->pandas-profiling) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from requests<2.29,>=2.24.0->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling) (0.5.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from tqdm<4.65,>=4.48.2->pandas-profiling) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml==1.0.12 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (1.0.12)\n",
      "Requirement already satisfied: xgboost>=0.90 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (1.6.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (1.4.4)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (1.23.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (1.1.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from flaml==1.0.12) (3.3.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from lightgbm>=2.3.1->flaml==1.0.12) (0.38.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas>=1.1.4->flaml==1.0.12) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from pandas>=1.1.4->flaml==1.0.12) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from scikit-learn>=0.24->flaml==1.0.12) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from scikit-learn>=0.24->flaml==1.0.12) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml==1.0.12) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (65.3.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 15.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in c:\\users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.3.0\n",
      "    Uninstalling setuptools-65.3.0:\n",
      "      Successfully uninstalled setuptools-65.3.0\n",
      "Successfully installed setuptools-65.6.3 wheel-0.38.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# instalación de la librerias.\n",
    "# La primera vez en ejecutarse demora unos minutos.\n",
    "%pip install -U setuptools wheel\n",
    "%pip install -U azure-datalake-utils\n",
    "%pip install pandas-profiling\n",
    "%pip install flaml==1.0.12\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinciar el kernel mediante la opción de VScode."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, se va abrir un navegador, el cualquier va requerir autenticación con el directorio activo de Haceb. Por favor usar las credenciales con las que acceden a aplicativos como `office365`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduar\\source\\plantilla-cientificos-ciudadanos\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from azure_datalake_utils import Datalake\n",
    "from flaml import AutoML\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "# configuración del datalake.\n",
    "DATALAKENAME = \"datalakeanaliticabi\"\n",
    "#dl = Datalake(DATALAKENAME, \"5368fc5a-2692-4a6a-b226-e2802e94e22b\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "\n",
    "Autora/Autor: Jhon/Jane Doe\n",
    "\n",
    "Correo: jane.doe@haceb.com\n",
    "\n",
    "Area: comercial\n",
    "\n",
    "Analitica por los cientificos ciudadanos\n",
    "\n",
    "El notebook tiene las siguiente secciones, estas son una sugerencia para mantener organizados todos los proyectos.\n",
    "\n",
    "1. Lectura de archivos desde el datalake.\n",
    "2. Exploración de datos.\n",
    "3. Transformación de datos (incluyendo escritura hacia el datalake).\n",
    "4. Entrenamiento y validación de modelos.\n",
    "5. Generación de predicciones.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivos desde el datalake"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que en el datalake tenemos dos tipos de contenedores/carpetas:\n",
    " \n",
    "- Contenedores curados: Se pueden reconocer por que tienen la palabra `curated` en su nombre. Algunos ejemplos: `hacebanalitica-curated-calidad`, `hacebanalitica-curated-servicio`. Estos contenedores tienen las siguiente reglas:\n",
    "    - Solo es posible leer información y no escribir.\n",
    "    - Cualquier modificación que se necesite en los archivos, debe ser coordinada con el equipo de arquitectura.\n",
    "- Contenedores de usuario: Se pueden reconcer por que tiene la palabra `user` en su nombre. Algunos ejemplos: `hacebanalitica-user-calidad`, `hacebanalitica-user-cientificos`. Estos contenedores tienen las siguiente reglas:\n",
    "    - Es posible leer y escribir información.\n",
    "    - La área correspondiente (ejemplo `calidad`), es la dueña de la información y pueden definir los cambios necesarios en coordinación con el equipo correspondiente.\n",
    "    - Si se encuentran en un proceso de experimentación, tratar de seguir el siguiente orden de prioridad:\n",
    "        - Usar el contenedor del área, ejemplo si el proyecto es de `calidad`, usar el contenedor `hacebanalitica-user-calidad`\n",
    "        - Si no se tiene disponibilidad del contenedor del area, usar `hacebanalitica-user-cientificos`. En futuros avances requerir al equipo de TI/Arquitectura la creación de un contenedor de usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_base = dl.read_csv(\"hacebanalitica-user-cientificos/prueba/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_excel = dl.read_excel(\"hacebanalitica-user-cientificos/prueba/diabetes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "with open(\"key.json\", 'r') as f:\n",
    "    key = json.loads(f.read())['key']\n",
    "\n",
    "dl = Datalake.from_account_key(DATALAKENAME, key)\n",
    "\n",
    "# leer todos la informacion existente del product name Nevera Himalaya Smart 448.\n",
    "# de las ultimas dos semanas\n",
    "now = pd.Timestamp.now().date() - relativedelta(days=1)\n",
    "fechas_a_cargar = [c.strftime(\"%Y_%m_%d\") for c in pd.date_range(start = now - relativedelta(days=15), end = now)]\n",
    "\n",
    "df = dl.read_csv_with_partition(ruta = \"hacebanalitica/raw/tuya_cloud/device_logs/\", \n",
    "    partition_inclusion =  {'product_name' : ['Haceb Pet Feeder'] , 'start_date':fechas_a_cargar},\n",
    "    sep = \"|\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>event_from</th>\n",
       "      <th>event_id</th>\n",
       "      <th>event_time</th>\n",
       "      <th>status</th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cold_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-26 12:59:44.842</td>\n",
       "      <td>1</td>\n",
       "      <td>-23</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-26 12:59:44.841</td>\n",
       "      <td>1</td>\n",
       "      <td>-14</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cool_temp_set</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-23 18:50:07.243</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>switch</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-21 13:14:53.767</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cool_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-21 13:14:53.767</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>cool_temp_set</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-12 15:23:26.861</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>cold_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-12 15:13:33.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>cold_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-12 15:13:32.564</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>cool_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-12 15:13:32.563</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>cool_temp_current</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-11 00:42:45.702</td>\n",
       "      <td>1</td>\n",
       "      <td>-29</td>\n",
       "      <td>ebc9bbba1414a04600a94c</td>\n",
       "      <td>Nevera Himalaya Smart 448</td>\n",
       "      <td>2022_12_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  code  event_from  event_id               event_time  status  \\\n",
       "0    cold_temp_current           1         7  2022-12-26 12:59:44.842       1   \n",
       "1    cool_temp_current           1         7  2022-12-26 12:59:44.841       1   \n",
       "2        cool_temp_set           1         7  2022-12-23 18:50:07.243       1   \n",
       "3               switch           1         7  2022-12-21 13:14:53.767       1   \n",
       "4    cool_temp_current           1         7  2022-12-21 13:14:53.767       1   \n",
       "..                 ...         ...       ...                      ...     ...   \n",
       "375      cool_temp_set           1         7  2022-12-12 15:23:26.861       1   \n",
       "376  cold_temp_current           1         7  2022-12-12 15:13:33.515       1   \n",
       "377  cold_temp_current           1         7  2022-12-12 15:13:32.564       1   \n",
       "378  cool_temp_current           1         7  2022-12-12 15:13:32.563       1   \n",
       "379  cool_temp_current           1         7  2022-12-11 00:42:45.702       1   \n",
       "\n",
       "     value                      id               product_name  start_date  \n",
       "0      -23  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_25  \n",
       "1      -14  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_25  \n",
       "2        5  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_23  \n",
       "3    false  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_20  \n",
       "4        0  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_20  \n",
       "..     ...                     ...                        ...         ...  \n",
       "375      6  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_12  \n",
       "376     -5  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_12  \n",
       "377     -6  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_12  \n",
       "378      3  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_12  \n",
       "379    -29  ebc9bbba1414a04600a94c  Nevera Himalaya Smart 448  2022_12_10  \n",
       "\n",
       "[380 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de datos\n",
    "\n",
    "Es cualquier experimento o proyecto, es ideal dejar en evidencia la descripción de los archivos que se van a usar. Se sugiere que esta exploración se realice usando la libreria [Pandas Profiling](https://pandas-profiling.ydata.ai/docs/master/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(informacion_base, title=\"Exploracion de datos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ver el reporte, por favor condensar las principales conclusiones de la exploración de datos, enfocarse en:\n",
    "\n",
    "1. Calidad de datos:\n",
    "    1. ¿Hay variables con valores faltantes?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "    2. ¿Hay variables con valores atípicos?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "2. Tendencias:\n",
    "    1. ¿Hay variables que tengan tendencias, ejemplo valores que se repiten mucho, o muy cercanos?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "    2. ¿ en que variables hay alta correlación?\n",
    "    \n",
    "\n",
    "3. Patrones insuales:\n",
    "    1. En problemas de clasificación, ¿hay clases que tengan más muestras que otras?\n",
    "\n",
    "    [escribir propias conclusiones]\n",
    "\n",
    "    2. En problema de regresión, ¿hay meses o epocas del año que tengan más valores?\n",
    "\n",
    "    [escribir propias conclusiones]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de datos\n",
    "\n",
    "En esta sección se deben aplicar las transformaciones que hayan a lugar. En lo posible solo usar operaciones de [Pandas](https://pandas.pydata.org/).\n",
    "\n",
    "Se muestran algunos ejemplos que sirven de inspiración, pero se sugiere explorar mucho más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover duplicados.\n",
    "informacion_base_dedup = informacion_base.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar valores mediante mapeo\n",
    "mapeo = {\n",
    "    0 : 'setosa',\n",
    "    1: 'versicolor',\n",
    "    2: 'virginica'\n",
    "}\n",
    "\n",
    "informacion_base['clase_nombre'] = informacion_base['class'].map(mapeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas.\n",
    "informacion_excel.rename(columns = {'bp': 'more_human_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizar variables.\n",
    "informacion_excel['progression_clase'] = pd.qcut(informacion_excel['progression'], \n",
    "    q = 5 , \n",
    "    labels = ['baja', 'media-baja', 'media', 'media-alta', 'alta'])\n",
    "\n",
    "informacion_excel[['progression_clase', 'progression']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer muestreo.\n",
    "informacion_base.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables dummy.\n",
    "pd.get_dummies(informacion_base, columns = ['clase_nombre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables dummy usando sklearn.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=True)\n",
    "onehot = enc.fit_transform(informacion_base[['clase_nombre']])\n",
    "#to print the encoded features for train data\n",
    "pd.DataFrame(onehot, columns=enc.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones sin cambiar la estructura.\n",
    "informacion_base['media sepal width (cm)'] = informacion_base.groupby(['class'])['sepal width (cm)'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones cambiando la estructura\n",
    "informacion_base_agg = informacion_base.groupby(['class'], as_index = False)['sepal width (cm)'].mean()\n",
    "informacion_base_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar dos dataframes.\n",
    "informacion_base_duplicada = pd.concat([informacion_base, informacion_base], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar dataframes.\n",
    "informacion_base_merge = informacion_base.merge(informacion_base_agg, on = ['class'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablas pivote.\n",
    "pivote = pd.pivot_table(informacion_excel, values = ['age', 'sex'], index = ['progression_clase'], aggfunc='sum')\n",
    "pivote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer Melt de dataframes.\n",
    "df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
    "                   'B': {0: 1, 1: 3, 2: 5},\n",
    "                   'C': {0: 2, 1: 4, 2: 6}})\n",
    "pd.melt(df, id_vars=['A'], value_vars=['B'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y validación de modelos\n",
    "\n",
    "En esta sección concentrarse en entrenar y validar el modelo. Dentro de esta sección se sugiere:\n",
    "\n",
    "1. Realizar la división de datos, conservar al menos un 10% de datos que no se usaran en el entrenamiento.\n",
    "2. Realizar entrenamiento usando herramientas AutoML. De esta manera la selección de parametros y modelos sera más eficiente. En la plantilla se sugiere usar las siguientes librerias:\n",
    "    1. [Fast Library for Automated Machine Learning & Tunning](https://microsoft.github.io/FLAML/).\n",
    "En un futuro se debe analizar otras librerias como [AutoGluon](https://auto.gluon.ai/stable/index.html) y [Auto-Sklearn](https://automl.github.io/auto-sklearn/master/). Por el momento por garantizar la estabilidad en el proceso, no es posible ofrecer un uso.\n",
    "\n",
    "En las siguiente secciones se muestran algunos ejemplos, para inspiarar el uso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# seperar las caracteristcas\n",
    "caracteristicas = ['sepal length (cm)', \n",
    "                   'sepal width (cm)', \n",
    "                   'petal length (cm)',\n",
    "                   'petal width (cm)']\n",
    "target = 'class'\n",
    "X = informacion_base[caracteristicas].copy()\n",
    "y = informacion_base[target].copy()\n",
    "# mantener random_state para reproducibilidad.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Advertencia!: Si el problema que se esta desarollando el tiempo es importante se debe usar un criterio de limites de fechas, ejemplo si se tiene un datos de tres años, se debe separar los ultimos meses para realizar la prueba. Usar las funciones de pandas para aplicar los filtros correspondientes. Un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limite_entrenamiento = '2017-09-01'\n",
    "entrenamiento = informacion_excel[informacion_excel['fecha']<limite_entrenamiento].copy()\n",
    "prueba = informacion_excel[informacion_excel['fecha']>=limite_entrenamiento].copy()\n",
    "#\n",
    "caracteristicas2 =['age', 'sex', 'bmi', 'bp', 's1', 's2']\n",
    "target2 = 'progression'\n",
    "X_train2 = entrenamiento[caracteristicas2].copy()\n",
    "y_train2 = entrenamiento[target2].copy()\n",
    "# \n",
    "X_test2 = entrenamiento[caracteristicas2].copy()\n",
    "y_test2 = entrenamiento[target2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificación FLAML. \n",
    "automl1 = AutoML()\n",
    "automl1.fit(X_train, y_train, task=\"classification\", time_budget = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saber las sugerencias de AUTOML.\n",
    "print(automl1.best_estimator)\n",
    "print(automl1.best_config)\n",
    "print(automl1.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener el mejor modelo.\n",
    "mejor_modelo_1 = automl1.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validar el mejor modelo.\n",
    "# usar la metrica más adecuada desde sklearn.\n",
    "from  sklearn import metrics\n",
    "y_pred = mejor_modelo_1.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión con FLAML.\n",
    "automl2 = AutoML()\n",
    "automl2.fit(X_train, y_train, task=\"regression\", time_budget = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saber las sugerencias de AUTOML.\n",
    "print(automl2.best_estimator)\n",
    "print(automl2.best_config)\n",
    "print(automl2.best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener el mejor modelo.\n",
    "mejor_modelo_2 = automl2.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validar el mejor modelo.\n",
    "# usar la metrica más adecuada desde sklearn.\n",
    "from  sklearn import metrics\n",
    "y_pred2 = mejor_modelo_2.predict(X_test2)\n",
    "print(metrics.mean_squared_error(y_test2, y_pred2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de predicciones\n",
    "\n",
    "Una vez se tenga el modelo seleccionado, las predicciones deben recibir las caracteristicas. Se sugiere a esas caracteristicas agregar como columna el valor predicho y guardar esas predicciones dentro del datalake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_a_predecir = pd.DataFrame(\n",
    "    {\n",
    "        'sepal length (cm)' : [4.6\t, 3.3, 4.1],\n",
    "        'sepal width (cm)' : [3.5, 3.6, 2.5],\n",
    "        'petal length (cm)' : [1.4, 5.4, 2.3],\n",
    "        'petal width (cm)' : [0.2, 2.3, 1.9],\n",
    "    }\n",
    ")\n",
    "base_a_predecir['class'] = mejor_modelo_1.predict(base_a_predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.write_excel(base_a_predecir, \"hacebanalitica-user-cientificos/prueba/iris_pred.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.write_csv(base_a_predecir, \"hacebanalitica-user-cientificos/prueba/iris_pred.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b145243b2ff1142fe66038d6c3bd724d42c01f344fdc8044c68da453fb6fddb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
